use faer::{Col, Mat, prelude::*};
use rand::rng;
use rand::seq::SliceRandom;
use rayon::prelude::*;
use std::time::Instant;

use csv::ReaderBuilder;
use std::error::Error;

pub struct StrideExplainer {
    n_samples: usize,
    m_landmarks: usize,
    z_matrices: Vec<Mat<f32>>, // ì„¼í„°ë§ëœ N x m ê·¼ì‚¬ í–‰ë ¬ë“¤
    y_mean: f32,               // ì „ì²´ í‰ê·  (Intercept)
    target_centered: Col<f32>, // í‰ê· ì´ ì œê±°ëœ y
}

impl StrideExplainer {
    /// ìƒˆë¡œìš´ STRIDE ì„¤ëª…ê¸° ìƒì„± ë° ì í•©(Fit)
    pub fn fit(x: &Mat<f32>, y: &Col<f32>, m_landmarks: usize, sigma: f32) -> Self {
        let n = x.nrows();
        let num_features = x.ncols();
        let y_mean = y.iter().sum::<f32>() / n as f32;
        let target_centered = y - Col::<f32>::full(n, y_mean);

        // 1. ê° ë³€ìˆ˜ë³„ë¡œ Nystrom ê·¼ì‚¬ ë° ì„¼í„°ë§ ìˆ˜í–‰
        let z_matrices: Vec<Mat<f32>> = (0..num_features)
            .into_par_iter() // ë³€ìˆ˜ë³„ ê³„ì‚° ë³‘ë ¬í™”
            .map(|f_idx| {
                let mut rng = rng();
                let mut indices: Vec<usize> = (0..n).collect();
                indices.shuffle(&mut rng);
                let landmark_indices = &indices[..m_landmarks];

                // K_nm (N x m) ê³„ì‚°
                let mut k_nm = Mat::<f32>::zeros(n, m_landmarks);
                for i in 0..n {
                    for (j_idx, &j) in landmark_indices.iter().enumerate() {
                        let diff = x[(i, f_idx)] - x[(j, f_idx)];
                        k_nm[(i, j_idx)] = (-(diff * diff) / (2.0 * sigma * sigma)).exp();
                    }
                }

                // K_mm (m x m) ê³„ì‚°
                let mut k_mm = Mat::<f32>::zeros(m_landmarks, m_landmarks);
                for (i_idx, &i) in landmark_indices.iter().enumerate() {
                    for (j_idx, &j) in landmark_indices.iter().enumerate() {
                        let diff = x[(i, f_idx)] - x[(j, f_idx)];
                        k_mm[(i_idx, j_idx)] = (-(diff * diff) / (2.0 * sigma * sigma)).exp();
                    }
                }

                // Z = K_nm * (K_mm)^-1/2
                let eig = k_mm
                    .self_adjoint_eigen(faer::Side::Lower)
                    .expect("Eigenvalue decomposition failed to converge");

                let s = eig.S(); // Eigenvalues (Col í˜•ì‹)
                let u = eig.U(); // Eigenvectors (Mat í˜•ì‹)
                let mut inv_sqrt_s = Mat::<f32>::zeros(m_landmarks, m_landmarks);
                for d in 0..m_landmarks {
                    // Diag íƒ€ì…ì€ ì¸ë±ì‹±ìœ¼ë¡œ ëŒ€ê° ì„±ë¶„ì— ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    let val = s[d];
                    inv_sqrt_s[(d, d)] = if val > 1e-10 { 1.0 / val.sqrt() } else { 0.0 };
                }
                let mut z = &k_nm * (u * &inv_sqrt_s);

                // --- Centering Step ---
                // ê° ì»¬ëŸ¼ì˜ í‰ê· ì„ êµ¬í•´ì„œ ëºŒ (Hilbert Space Projection)
                for j in 0..m_landmarks {
                    let col_mean = z.col(j).iter().sum::<f32>() / n as f32;
                    for i in 0..n {
                        z[(i, j)] -= col_mean;
                    }
                }
                z
            })
            .collect();

        Self {
            n_samples: n,
            m_landmarks,
            z_matrices,
            y_mean,
            target_centered,
        }
    }

    /// ëª¨ë“  ë³€ìˆ˜ì˜ ê¸°ì—¬ë„ë¥¼ ê³„ì‚° (Global Solve)
    pub fn compute_contributions(&self, lambda: f32) -> Vec<Col<f32>> {
        let n_features = self.z_matrices.len();
        let total_m = n_features * self.m_landmarks;

        // 2. ì „ì²´ ì„¤ê³„ í–‰ë ¬ Z_total êµ¬ì„± [Z1, Z2, ..., ZM] (N x total_m)
        let mut z_total = Mat::<f32>::zeros(self.n_samples, total_m);
        for (f_idx, z) in self.z_matrices.iter().enumerate() {
            let offset = f_idx * self.m_landmarks;
            for j in 0..self.m_landmarks {
                for i in 0..self.n_samples {
                    z_total[(i, offset + j)] = z[(i, j)];
                }
            }
        }

        // 3. Ridge Regression ìˆ˜í–‰: (Z^T Z + lambda*I) alpha = Z^T y
        let zt_z = z_total.transpose() * &z_total;
        let mut lhs = zt_z;
        for i in 0..total_m {
            lhs[(i, i)] += lambda;
        }

        let rhs = z_total.transpose() * &self.target_centered;

        // Cholesky ë¶„í•´ë¡œ alpha êµ¬í•˜ê¸°
        let alpha = lhs
            .ldlt(faer::Side::Lower)
            .expect("Cholesky decomposition failed")
            .solve(&rhs);

        // 4. ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë³µì› f_i = Z_i * alpha_i
        (0..n_features)
            .map(|f_idx| {
                let offset = f_idx * self.m_landmarks;
                let alpha_i = alpha.get(offset..offset + self.m_landmarks);
                &self.z_matrices[f_idx] * alpha_i
            })
            .collect()
    }
}

// --- CSV ë¡œë” í•¨ìˆ˜ ---
fn load_csv_to_mat(path: &str) -> Mat<f32> {
    let mut rdr = ReaderBuilder::new()
        .has_headers(false)
        .from_path(path)
        .unwrap();
    let mut v = Vec::new();
    let mut nrows = 0;

    for result in rdr.records() {
        let record = result.unwrap();
        nrows += 1;
        for field in record.iter() {
            v.push(field.parse::<f32>().unwrap());
        }
    }
    let ncols = v.len() / nrows;

    // faerì—ì„œ ê°€ì¥ ê¶Œì¥í•˜ëŠ” 'í•¨ìˆ˜í˜• ìƒì„±' ë°©ì‹ì…ë‹ˆë‹¤.
    // (i, j) ì¢Œí‘œë¥¼ ë°›ì•„ ë²¡í„° vì—ì„œ ê°’ì„ ì°¾ì•„ ë§¤í•‘í•©ë‹ˆë‹¤.
    Mat::from_fn(nrows, ncols, |i, j| v[i * ncols + j])
}

// ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±ì´ Column Major ê¸°ì¤€ì´ë¯€ë¡œ row-majorì¸ CSVëŠ” ë³€í™˜ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
// ì•„ë˜ëŠ” ì•ˆì „í•œ Row-major ë¡œë”© ë°©ì‹ì…ë‹ˆë‹¤.
fn load_csv_to_col(path: &str) -> Col<f32> {
    let mut rdr = ReaderBuilder::new()
        .has_headers(false)
        .from_path(path)
        .unwrap();
    let mut v = Vec::new();
    for result in rdr.records() {
        let record = result.unwrap();
        v.push(record[0].parse::<f32>().unwrap());
    }
    let nrows = v.len();
    Col::from_fn(nrows, |i| v[i])
}
fn spearman_correlation(a: &[f32], b: &[f32]) -> f32 {
    let n = a.len();
    if n < 2 {
        return 1.0;
    }

    fn get_ranks(data: &[f32]) -> Vec<f32> {
        let n = data.len();
        let mut indexed: Vec<(usize, f32)> = data.iter().cloned().enumerate().collect();
        // ê°’ ê¸°ì¤€ ì •ë ¬
        indexed.sort_by(|x, y| x.1.partial_cmp(&y.1).unwrap());

        let mut ranks = vec![0.0; n];
        let mut i = 0;
        while i < n {
            let mut j = i + 1;
            // ê°’ì´ ê°™ì€ êµ¬ê°„(ë™ì ì) ì°¾ê¸°
            while j < n && indexed[j].1 == indexed[i].1 {
                j += 1;
            }
            // ë™ì ìë“¤ì—ê²Œ í‰ê·  ìˆœìœ„ ë¶€ì—¬ (e.g., 1ìœ„ì™€ 2ìœ„ê°€ ê°™ìœ¼ë©´ ë‘˜ ë‹¤ 1.5ìœ„)
            let avg_rank = (i + j - 1) as f32 / 2.0;
            for k in i..j {
                ranks[indexed[k].0] = avg_rank;
            }
            i = j;
        }
        ranks
    }

    let a_ranks = get_ranks(a);
    let b_ranks = get_ranks(b);

    let mut d_squared_sum = 0.0f64; // ì •ë°€ë„ë¥¼ ìœ„í•´ f64 ì‚¬ìš©
    for i in 0..n {
        let diff = (a_ranks[i] - b_ranks[i]) as f64;
        d_squared_sum += diff * diff;
    }

    let nf = n as f64;
    let res = 1.0 - (6.0 * d_squared_sum) / (nf * (nf * nf - 1.0));
    res as f32
}

fn main() {
    println!("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...");
    let x = load_csv_to_mat("real_x.csv");
    let y_pred_rf = load_csv_to_col("real_y_pred.csv").to_owned(); // Col í˜•íƒœë¡œ ë³€í™˜

    println!("ğŸš€ STRIDE ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ (N={}, M={})", x.nrows(), x.ncols());
    let start_total = Instant::now();

    // 1. Fit (Nystrom + Centering)
    let m_landmarks = 100;
    let sigma = 0.3;
    let lambda = 0.1; // ldlt ì•ˆì •ì„±ì„ ìœ„í•´ ì•½ê°„ ë†’ê²Œ ì‹œì‘

    let explainer = StrideExplainer::fit(&x, &y_pred_rf, m_landmarks, sigma);

    // 2. Solve (f64 Hybrid ì¶”ì²œ)
    let contributions = explainer.compute_contributions(lambda);

    let duration = start_total.elapsed();
    println!("âœ… STRIDE ì™„ë£Œ: {:.4}s", duration.as_secs_f64());

    // 3. R-squared (Fidelity) ê³„ì‚°
    let n = x.nrows();
    let mut y_hat = Col::<f32>::full(n, explainer.y_mean);
    for contrib in &contributions {
        y_hat = y_hat + contrib;
    }

    let rss: f32 = (0..n).map(|i| (y_pred_rf[i] - y_hat[i]).powi(2)).sum();
    let tss: f32 = (0..n)
        .map(|i| (y_pred_rf[i] - explainer.y_mean).powi(2))
        .sum();
    let r2 = 1.0 - (rss / tss);

    println!("{:-<40}", "");
    println!("ğŸ“Š Fidelity (R^2 to RF): {:.6}", r2);
    println!("{:-<40}", "");

    // 4. ë³€ìˆ˜ë³„ ì¤‘ìš”ë„ (Global Importance) ì¶œë ¥
    println!("ğŸ’¡ ë³€ìˆ˜ë³„ í‰ê·  ì ˆëŒ€ ê¸°ì—¬ë„ (Importance):");
    for (i, contrib) in contributions.iter().enumerate() {
        let avg_imp: f32 = contrib.iter().map(|v| v.abs()).sum::<f32>() / n as f32;
        println!("Feature {:02}: {:.6}", i, avg_imp);
    }
    println!("ğŸ” TreeSHAPê³¼ì˜ ìœ ì‚¬ë„ ì¸¡ì • ì¤‘...");
    let tree_shap_data = load_csv_to_mat("real_tree_shap.csv");
    let mut correlations = Vec::new();

    for i in 0..x.ncols() {
        let stride_imp: Vec<f32> = (0..n).map(|idx| contributions[i][idx]).collect();

        // TreeSHAP ê¸°ì—¬ë„ë¥¼ Vec<f32>ë¡œ ë³µì‚¬
        let tree_col = tree_shap_data.col(i);
        let tree_imp: Vec<f32> = (0..n).map(|idx| tree_col[idx]).collect();
        correlations.push(spearman_correlation(&stride_imp, &tree_imp));
    }

    let avg_spearman = correlations.iter().sum::<f32>() / correlations.len() as f32;
    println!("ğŸ“ˆ Average Spearman Correlation: {:.6}", avg_spearman);
}

// fn main() {
//     // --- ì„¤ì • (Big Data Scenario) ---
//     let n = 100_000; // 10ë§Œ ìƒ˜í”Œ
//     let m_features = 50; // 50ê°œ ë³€ìˆ˜
//     let l_landmarks = 200; // ë³€ìˆ˜ë‹¹ ëœë“œë§ˆí¬ ìˆ˜

//     println!(
//         "ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘: N={}, M={}, Landmarks={}",
//         n, m_features, l_landmarks
//     );

//     // 1. ê°€ìƒ ë°ì´í„° ìƒì„± ì‹œê°„ ì¸¡ì •
//     let start_data = Instant::now();
//     let mut x = Mat::<f32>::zeros(n, m_features);
//     let mut y = Col::<f32>::zeros(n);
//     // (ë°ì´í„° ìƒì„± ë¡œì§ ìƒëµ - ì´ì „ê³¼ ë™ì¼í•˜ë˜ ë£¨í”„ë§Œ í™•ì¥)
//     println!("âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ: {:?}", start_data.elapsed());

//     // 2. STRIDE Fit (Nystrom + Centering) ì‹œê°„ ì¸¡ì •
//     // ì´ ë‹¨ê³„ëŠ” ë³€ìˆ˜ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬(Rayon)ë©ë‹ˆë‹¤.
//     let start_fit = Instant::now();
//     let explainer = StrideExplainer::fit(&x, &y, l_landmarks, 1.0);
//     let fit_duration = start_fit.elapsed();
//     println!("âš¡ STRIDE Fit ì™„ë£Œ (ë³‘ë ¬ ì²˜ë¦¬): {:?}", fit_duration);

//     // 3. Global Solve (Ridge Regression) ì‹œê°„ ì¸¡ì •
//     // Z_total (100,000 x 10,000) í–‰ë ¬ ì—°ì‚° êµ¬ê°„
//     let start_solve = Instant::now();
//     let contributions = explainer.compute_contributions(1e-4);
//     let solve_duration = start_solve.elapsed();
//     println!("ğŸ§  Global Solve ì™„ë£Œ: {:?}", solve_duration);

//     println!("------------------------------------------------------------");
//     println!("ì´ ì†Œìš” ì‹œê°„: {:?}", fit_duration + solve_duration);
// }

// fn main() {
//     // ì˜ˆì‹œ ë°ì´í„° ìƒì„± (N=1000, Features=3)
//     let n = 100000; // ìƒ˜í”Œ ìˆ˜
//     let m = 3; // íŠ¹ì„± ìˆ˜

//     // 1. ì…ë ¥ ë°ì´í„° X ìƒì„±: -3.0 ~ 3.0 ì‚¬ì´ì˜ ëœë¤ ê°’
//     let mut x = Mat::<f32>::zeros(n, m);
//     for i in 0..n {
//         for j in 0..m {
//             x[(i, j)] = (rand::random::<f32>() - 0.5) * 6.0;
//         }
//     }
//     let mut y = Col::<f32>::zeros(n);
//     for i in 0..n {
//         let f1 = x[(i, 0)].sin();
//         let f2 = x[(i, 1)].powi(2);
//         let f3 = x[(i, 2)] * 0.5;
//         y[i] = f1 + f2 + f3;
//     }

//     // STRIDE ì‹¤í–‰
//     let explainer = StrideExplainer::fit(&x, &y, 200, 1.0);
//     let contributions = explainer.compute_contributions(1e-4);

//     // 4. ê²°ê³¼ ê²€ì¦ (ì²« 10ê°œ ìƒ˜í”Œì— ëŒ€í•´ ì •ë‹µê³¼ ë¹„êµ)
//     println!(
//         "{:<10} | {:<10} | {:<10} | {:<10}",
//         "Sample", "True f1", "Pred f1", "Diff"
//     );
//     println!("------------------------------------------------------------");

//     // Centering ë•Œë¬¸ì— Pred ê°’ì€ ì ˆëŒ€ê°’ì´ ì•„ë‹ˆë¼ 'í‰ê· ìœ¼ë¡œë¶€í„°ì˜ í¸ì°¨'ì…ë‹ˆë‹¤.
//     // ë¹„êµë¥¼ ìœ„í•´ ì •ë‹µ f1ë„ í‰ê· ì„ ë¹¼ì„œ ë¹„êµí•˜ê±°ë‚˜, ìƒê´€ê³„ìˆ˜ë¥¼ ë´…ë‹ˆë‹¤.
//     for i in 0..10 {
//         let true_f1 = x[(i, 0)].sin();
//         let pred_f1 = contributions[0][i];

//         // ì£¼ì˜: pred_f1ì€ centering ë˜ì–´ ìˆì–´ ì˜¤í”„ì…‹ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
//         // ì—¬ê¸°ì„œëŠ” íë¦„(ê²½í–¥ì„±)ì´ ë§ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
//         println!(
//             "{:<10} | {:<10.4} | {:<10.4} | {:<10.4}",
//             i,
//             true_f1,
//             pred_f1,
//             (true_f1 - pred_f1).abs()
//         );
//     }

//     let mut rss = 0.0;
//     let mut tss = 0.0;
//     let y_mean = y.iter().sum::<f32>() / n as f32;

//     for i in 0..n {
//         let mut pred_y = explainer.y_mean;
//         for j in 0..m {
//             pred_y += contributions[j][i];
//         }
//         rss += (y[i] - pred_y).powi(2);
//         tss += (y[i] - y_mean).powi(2);
//     }

//     println!("------------------------------------------------------------");
//     println!("R-squared: {:.4}", 1.0 - (rss / tss));
// }
